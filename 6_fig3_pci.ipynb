{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "# ------------------------------------------------------\n",
    "## The notebook contains the following sections:\n",
    "\n",
    "### 1) List of installed and imported packages: \n",
    "The packages used for analysis running on Python 3.8 (Windows 10). Install the \"phy2\" environment.\n",
    "\n",
    "### 2) Functions: \n",
    "A collection of functions to calculate the perturbational complexity index (PCI) and appending the results to a dataframe.\n",
    " \n",
    "PCI st was calculated as described in:\n",
    "Comolatti R et al., \"A fast and general method to empirically estimate the complexity of brain responses\n",
    "to transcranial and intracranial stimulations\" Brain Stimulation (in press)\n",
    "https://doi.org/10.1016/j.brs.2019.05.013\n",
    "\n",
    "\n",
    "### 3) Parameters: \n",
    "General information (arguments) passed to functions in section 4. The file paths of the dataframe containing pci measures are specified here. \n",
    "\n",
    "### 4) Call functions: \n",
    "The functions specified in section 3 are executed here. \n",
    "\n",
    "# ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) List of imported and installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n",
    "Package                       Version\n",
    "----------------------------- -------------------\n",
    "alabaster                     0.7.12\n",
    "argh                          0.26.2\n",
    "argon2-cffi                   20.1.0\n",
    "astroid                       2.4.2\n",
    "async-generator               1.10\n",
    "atomicwrites                  1.4.0\n",
    "attrs                         20.2.0\n",
    "autopep8                      1.5.4\n",
    "Babel                         2.8.0\n",
    "backcall                      0.2.0\n",
    "bcrypt                        3.2.0\n",
    "bleach                        3.2.1\n",
    "brotlipy                      0.7.0\n",
    "certifi                       2020.12.5\n",
    "cffi                          1.14.3\n",
    "chardet                       3.0.4\n",
    "click                         7.1.2\n",
    "cloudpickle                   1.6.0\n",
    "colorama                      0.4.4\n",
    "colorcet                      2.0.2\n",
    "cryptography                  3.1.1\n",
    "cycler                        0.10.0\n",
    "Cython                        0.29.21\n",
    "dask                          2.22.0\n",
    "decorator                     4.4.2\n",
    "defusedxml                    0.6.0\n",
    "diff-match-patch              20200713\n",
    "docutils                      0.16\n",
    "entrypoints                   0.3\n",
    "flake8                        3.8.4\n",
    "future                        0.18.2\n",
    "h5py                          2.10.0\n",
    "idna                          2.10\n",
    "imagesize                     1.2.0\n",
    "importlib-metadata            2.0.0\n",
    "intervaltree                  3.1.0\n",
    "ipykernel                     5.3.4\n",
    "ipython                       7.18.1\n",
    "ipython-genutils              0.2.0\n",
    "isort                         5.6.4\n",
    "jedi                          0.17.2\n",
    "Jinja2                        3.0.0a1\n",
    "joblib                        0.16.0\n",
    "json5                         0.9.5\n",
    "jsonschema                    3.2.0\n",
    "jupyter-client                6.1.7\n",
    "jupyter-core                  4.6.3\n",
    "jupyterlab                    2.2.6\n",
    "jupyterlab-pygments           0.1.2\n",
    "jupyterlab-server             1.2.0\n",
    "keyring                       21.4.0\n",
    "kiwisolver                    1.2.0\n",
    "lazy-object-proxy             1.4.3\n",
    "livereload                    2.6.2\n",
    "lunr                          0.5.8\n",
    "Markdown                      3.2.2\n",
    "MarkupSafe                    2.0.0a1\n",
    "matplotlib                    3.2.2\n",
    "matplotlib-scalebar           0.7.2\n",
    "mccabe                        0.6.1\n",
    "MEAutility                    1.4.8\n",
    "mistune                       0.8.4\n",
    "mkdocs                        1.1.2\n",
    "mkl-fft                       1.1.0\n",
    "mkl-random                    1.1.1\n",
    "mkl-service                   2.3.0\n",
    "mtscomp                       1.0.1\n",
    "nbclient                      0.5.1\n",
    "nbconvert                     6.0.7\n",
    "nbformat                      5.0.8\n",
    "nest-asyncio                  1.4.1\n",
    "networkx                      2.5\n",
    "nltk                          3.5\n",
    "notebook                      6.1.4\n",
    "numpy                         1.19.1\n",
    "numpydoc                      1.1.0\n",
    "olefile                       0.46\n",
    "packaging                     20.4\n",
    "pandas                        1.1.4\n",
    "pandocfilters                 1.4.2\n",
    "param                         1.9.3\n",
    "paramiko                      2.7.2\n",
    "parso                         0.7.1\n",
    "pathtools                     0.1.2\n",
    "pexpect                       4.8.0\n",
    "phy                           2.0b1\n",
    "phylib                        2.2\n",
    "pickleshare                   0.7.5\n",
    "Pillow                        7.2.0\n",
    "pip                           20.2.1\n",
    "pluggy                        0.13.1\n",
    "prometheus-client             0.8.0\n",
    "prompt-toolkit                3.0.8\n",
    "psutil                        5.7.2\n",
    "pycodestyle                   2.6.0\n",
    "pycparser                     2.20\n",
    "pyct                          0.4.6\n",
    "pydocstyle                    5.1.1\n",
    "pyflakes                      2.2.0\n",
    "Pygments                      2.7.2\n",
    "pyintan                       0.2.0\n",
    "pylint                        2.6.0\n",
    "PyNaCl                        1.4.0\n",
    "PyOpenGL                      3.1.5\n",
    "pyOpenSSL                     19.1.0\n",
    "pyparsing                     2.4.7\n",
    "pyreadline                    2.1\n",
    "pyrsistent                    0.17.3\n",
    "PySocks                       1.7.1\n",
    "python-dateutil               2.8.1\n",
    "python-jsonrpc-server         0.4.0\n",
    "python-language-server        0.35.1\n",
    "pytz                          2020.1\n",
    "pywin32                       228\n",
    "pywin32-ctypes                0.2.0\n",
    "pywinpty                      0.5.7\n",
    "PyYAML                        5.3.1\n",
    "pyzmq                         19.0.2\n",
    "QDarkStyle                    2.8.1\n",
    "QtAwesome                     1.0.1\n",
    "qtconsole                     4.7.7\n",
    "QtPy                          1.9.0Note: you may need to restart the kernel to use updated packages.\n",
    "\n",
    "quantities                    0.12.4\n",
    "regex                         2020.7.14\n",
    "requests                      2.24.0\n",
    "rope                          0.18.0\n",
    "Rtree                         0.9.4\n",
    "scikit-learn                  0.23.1\n",
    "scipy                         1.5.0\n",
    "seaborn                       0.11.0\n",
    "Send2Trash                    1.5.0\n",
    "setuptools                    49.2.1.post20200807\n",
    "six                           1.15.0\n",
    "snowballstemmer               2.0.0\n",
    "sortedcontainers              2.2.2\n",
    "Sphinx                        3.2.1\n",
    "sphinxcontrib-applehelp       1.0.2\n",
    "sphinxcontrib-devhelp         1.0.2\n",
    "sphinxcontrib-htmlhelp        1.0.3\n",
    "sphinxcontrib-jsmath          1.0.1\n",
    "sphinxcontrib-qthelp          1.0.3\n",
    "sphinxcontrib-serializinghtml 1.1.4\n",
    "spikecomparison               0.3.0\n",
    "spikeextractors               0.9.2\n",
    "spikefeatures                 0.1.1\n",
    "spikeinterface                0.10.0\n",
    "spikemetrics                  0.2.2\n",
    "spikesorters                  0.4.2\n",
    "spiketoolkit                  0.7.1\n",
    "spikewidgets                  0.5.0\n",
    "spyder                        4.1.5\n",
    "spyder-kernels                1.9.4\n",
    "terminado                     0.9.1\n",
    "testpath                      0.4.4\n",
    "threadpoolctl                 2.1.0\n",
    "toml                          0.10.1\n",
    "toolz                         0.10.0\n",
    "tornado                       6.0.4\n",
    "tqdm                          4.48.2\n",
    "traitlets                     5.0.5\n",
    "typed-ast                     1.4.1\n",
    "ujson                         4.0.1\n",
    "urllib3                       1.25.11\n",
    "watchdog                      0.10.3\n",
    "wcwidth                       0.2.5\n",
    "webencodings                  0.5.1\n",
    "wheel                         0.34.2\n",
    "win-inet-pton                 1.1.0\n",
    "wincertstore                  0.2\n",
    "wrapt                         1.11.2\n",
    "yapf                          0.30.0\n",
    "zipp                          3.4.0¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import scipy.signal\n",
    "import os\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_PCIst(signal_evk, times, full_return=False, **par):\n",
    "    ''' Calculates PCIst (Perturbational Complexity Index based on State transitions) of a signal.\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_evk : ndarray\n",
    "        2D array (ch, times) containing signal.\n",
    "    times : ndarray\n",
    "        1D array (time,) containing timepoints (negative values are baseline).\n",
    "    full_return : bool\n",
    "        Returns multiple variables involved in PCI computation.\n",
    "    **pars : dictionary\n",
    "        Dictionary containing parameters (see dimensionality_reduction(),\n",
    "        state_transition_quantification()and preprocess_signal() documentation).\n",
    "        Example:\n",
    "        >> par = {'baseline_window':(-400,-50), 'response_window':(0,300), 'k':1.2, 'min_snr':1.1,\n",
    "        'max_var':99, 'embed':False,'n_steps':100}\n",
    "        >> PCIst, PCIst_bydim = calc_PCIst(signal_evoked, times, **par)\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        PCIst value\n",
    "    OR (if full_return==True)\n",
    "    dict\n",
    "        Dictionary containing all variables from calculation including array 'dNSTn' with PCIst decomposition.\n",
    "    '''\n",
    "    \n",
    "    #evaluate function (don't forget to # the variables when done evaluating)\n",
    "    #signal_evk = data_pci\n",
    "    #times = time\n",
    "\n",
    "    \n",
    "    if np.any(np.isnan(signal_evk)):\n",
    "        print('Data contains nan values.')\n",
    "        return 0\n",
    "\n",
    "    signal_evk, times = preprocess_signal(signal_evk, times, (par['baseline_window'][0],\n",
    "                                                              par['response_window'][1]), **par)\n",
    "    signal_svd, var_exp, eigenvalues, snrs = dimensionality_reduction(signal_evk, times, **par)\n",
    "    STQ = state_transition_quantification(signal_svd, times, **par)\n",
    "\n",
    "    PCI = np.sum(STQ['dNST'])\n",
    "\n",
    "    if full_return:\n",
    "        return {'PCI':PCI, **STQ, 'signal_evk':signal_evk, 'times':times, 'signal_svd':signal_svd,\n",
    "                'eigenvalues':eigenvalues, 'var_exp':var_exp, 'snrs':snrs}\n",
    "    return PCI\n",
    "\n",
    "## DIMENSIONALITY REDUCTION\n",
    "def dimensionality_reduction(signal, times, response_window, max_var=0.99, min_snr=1.1,\n",
    "                             n_components=None, **kwargs):\n",
    "    '''Returns principal components of signal according to SVD of the response.\n",
    "    Calculates SVD at a given time interval (response_window) and uses the new basis to transform\n",
    "    the whole signal yielding `n_components` principal components. The principal components are\n",
    "    then selected to account for at least `max_var`% of the variance basesent in the signal's\n",
    "    response.\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray\n",
    "        2D array (ch,time) containing signal.\n",
    "    times : ndarray\n",
    "        1D array (time,) containing timepoints\n",
    "    response_window : tuple\n",
    "        Signal's response time interval (ini,end).\n",
    "    max_var: 0 < float <= 100\n",
    "        Percentage of variance accounted for by the selected principal components.\n",
    "    min_snr : float, optional\n",
    "        Selects principal components with a signal-to-noise ratio (SNR) > min_snr.\n",
    "    n_components : int, optional\n",
    "        Number of principal components calculated (before selection).\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        2D array (ch,time) with selected principal components.\n",
    "    np.ndarray\n",
    "        1D array (n_components,) with `n_components` SVD eigenvalues of the signal's response.\n",
    "    '''\n",
    "\n",
    "    #evaluate function (don't forget to # the variables when done evaluating)\n",
    "    #signal = data_pci\n",
    "    #times = time\n",
    "    #n_components=None\n",
    "    #response_window = par['response_window']\n",
    "    \n",
    "    \n",
    "    #if 'None' is given as an argument, the number of components corresponds to the number of channels of the input data \n",
    "    if not n_components:\n",
    "        n_components = signal.shape[0]\n",
    "        \n",
    "    Vk, eigenvalues = get_svd(signal, times, response_window, n_components)\n",
    "    var_exp = 100 * eigenvalues**2/np.sum(eigenvalues**2)\n",
    "\n",
    "    signal_svd = apply_svd(signal, Vk)\n",
    "\n",
    "    max_dim = calc_maxdim(eigenvalues, max_var)\n",
    "\n",
    "    signal_svd = signal_svd[:max_dim, :]\n",
    "\n",
    "    # if min_snr:\n",
    "        # base_ini_ix = get_time_index(times, kwargs['baseline_window'][0])\n",
    "        # base_end_ix = get_time_index(times, kwargs['baseline_window'][1])\n",
    "        # resp_ini_ix = get_time_index(times, response_window[0])\n",
    "        # resp_end_ix = get_time_index(times, response_window[1])\n",
    "        # n_dims = np.size(signal_svd, 0)\n",
    "        # snrs = np.zeros(n_dims)\n",
    "        # for c in range(n_dims):\n",
    "        #     resp_power = np.mean(np.square(signal_svd[c, resp_ini_ix:resp_end_ix]))\n",
    "        #     base_power = np.mean(np.square(signal_svd[c, base_ini_ix:base_end_ix]))\n",
    "        #     snrs[c] = np.sqrt(np.divide(resp_power, base_power))\n",
    "    snrs = calc_snr(signal_svd, times, kwargs['baseline_window'], response_window)\n",
    "    signal_svd = signal_svd[snrs > min_snr, :]\n",
    "    snrs = snrs[snrs > min_snr]\n",
    "\n",
    "    Nc = signal_svd.shape[0]\n",
    "\n",
    "    return signal_svd, var_exp[:Nc], eigenvalues, snrs\n",
    "\n",
    "def calc_snr(signal_svd, times, baseline_window, response_window):\n",
    "\n",
    "    base_ini_ix = get_time_index(times, baseline_window[0])\n",
    "    base_end_ix = get_time_index(times, baseline_window[1])\n",
    "    resp_ini_ix = get_time_index(times, response_window[0])\n",
    "    resp_end_ix = get_time_index(times, response_window[1])\n",
    "\n",
    "    resp_power = np.mean(np.square(signal_svd[:,resp_ini_ix:resp_end_ix]), axis=1)\n",
    "    base_power = np.mean(np.square(signal_svd[:,base_ini_ix:base_end_ix]), axis=1)\n",
    "    snrs = np.sqrt(resp_power / base_power)\n",
    "    return snrs\n",
    "\n",
    "def get_svd(signal_evk, times, response_window, n_components):\n",
    "        \n",
    "    #defines the response window, specified in par dictionary\n",
    "    ini_t, end_t = response_window\n",
    "    #get start index of response_window\n",
    "    ini_ix = get_time_index(times, onset=ini_t)\n",
    "    #get stop index value of response window\n",
    "    end_ix = get_time_index(times, onset=end_t)\n",
    "    \n",
    "    #slice preprocessed signal and transpose data (channel X samples to samples x channels)\n",
    "    signal_resp = signal_evk[:, ini_ix:end_ix].T\n",
    "    \n",
    "    U, S, V = linalg.svd(signal_resp, full_matrices=False)\n",
    "    V = V.T\n",
    "    Vk = V[:, :n_components]\n",
    "    eigenvalues = S[:n_components]\n",
    "    return Vk, eigenvalues\n",
    "\n",
    "def apply_svd(signal, V):\n",
    "    '''Transforms signal according to SVD basis.'''\n",
    "    return signal.T.dot(V).T\n",
    "\n",
    "## STATE TRANSITION QUANTIFICATION\n",
    "def state_transition_quantification(signal, times, k, baseline_window, response_window, embed=False,\n",
    "                                    L=None, tau=None, n_steps=100, max_thr_p=1.0, **kwargs):\n",
    "    ''' Receives selected principal components of perturbational signal and\n",
    "    performs state transition quantification.\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray\n",
    "        2D array (component,time) containing signal (typically, the selected\n",
    "        principal components).\n",
    "    times : ndarray\n",
    "        1D array (time,) containing timepoints\n",
    "    k : float > 1\n",
    "        Noise control parameter.\n",
    "    baseline_window : tuple\n",
    "        Signal's baseline time interval (ini,end).\n",
    "    response_window : tuple\n",
    "        Signal's response time interval (ini,end).\n",
    "    embed : bool, optional\n",
    "        Perform time-delay embedding.\n",
    "    L : int\n",
    "        Number of embedding dimensions.\n",
    "    tau : int\n",
    "        Number of timesamples of embedding delay\n",
    "    n_steps : int, optional\n",
    "        Number of steps used to search for the threshold that maximizes ∆NST.\n",
    "        Search is performed by partitioning  the interval (defined from the median\n",
    "        of the baseline’s distance matrix to the maximum of the response’s\n",
    "        distance matrix) into ‘n_steps’ equal lengths.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        PCIst value.\n",
    "    ndarray\n",
    "        List containing component wise PCIst value (∆NSTn).\n",
    "    '''\n",
    "\n",
    "    n_dims = signal.shape[0]\n",
    "    if n_dims == 0:\n",
    "        print('No components --> PCIst=0')\n",
    "        return {'dNST':np.array([]), 'n_dims':0}\n",
    "\n",
    "    # EMBEDDING\n",
    "    if embed:\n",
    "        cut = (L-1)*tau\n",
    "        times = times[cut:]\n",
    "        temp_signal = np.zeros((n_dims, L, len(times)))\n",
    "        for i in range(n_dims):\n",
    "            temp_signal[i, :, :] = dimension_embedding(signal[i, :], L, tau)\n",
    "        signal = temp_signal\n",
    "\n",
    "    else:\n",
    "        signal = signal[:, np.newaxis, :]\n",
    "\n",
    "    # BASELINE AND RESPONSE DEFINITION\n",
    "    base_ini_ix = get_time_index(times, baseline_window[0])\n",
    "    base_end_ix = get_time_index(times, baseline_window[1])\n",
    "    resp_ini_ix = get_time_index(times, response_window[0])\n",
    "    resp_end_ix = get_time_index(times, response_window[1])\n",
    "    n_baseline = len(times[base_ini_ix:base_end_ix])\n",
    "    n_response = len(times[resp_ini_ix:resp_end_ix])\n",
    "\n",
    "    if n_response <= 1 or n_baseline <= 1:\n",
    "        print('Warning: Bad time interval defined.')\n",
    "\n",
    "    baseline = signal[:, :, base_ini_ix:base_end_ix]\n",
    "    response = signal[:, :, resp_ini_ix:resp_end_ix]\n",
    "\n",
    "    # NST CALCULATION\n",
    "        # Distance matrix\n",
    "    D_base = np.zeros((n_dims, n_baseline, n_baseline))\n",
    "    D_resp = np.zeros((n_dims, n_response, n_response))\n",
    "        # Transition matrix\n",
    "    T_base = np.zeros((n_steps, n_dims, n_baseline, n_baseline))\n",
    "    T_resp = np.zeros((n_steps, n_dims, n_response, n_response))\n",
    "        # Number of state transitions\n",
    "    NST_base = np.zeros((n_steps, n_dims))\n",
    "    NST_resp = np.zeros((n_steps, n_dims))\n",
    "    thresholds = np.zeros((n_steps, n_dims))\n",
    "    for i in range(n_dims):\n",
    "        D_base[i, :, :] = recurrence_matrix(baseline[i, :, :], thr=None, mode='distance')\n",
    "        D_resp[i, :, :] = recurrence_matrix(response[i, :, :], thr=None, mode='distance')\n",
    "        min_thr = np.median(D_base[i, :, :].flatten())\n",
    "        max_thr = np.max(D_resp[i, :, :].flatten()) * max_thr_p\n",
    "        thresholds[:, i] = np.linspace(min_thr, max_thr, n_steps)\n",
    "    for i in range(n_steps):\n",
    "        for j in range(n_dims):\n",
    "            T_base[i, j, :, :] = distance2transition(D_base[j, :, :], thresholds[i, j])\n",
    "            T_resp[i, j, :, :] = distance2transition(D_resp[j, :, :], thresholds[i, j])\n",
    "\n",
    "            NST_base[i, j] = np.sum(T_base[i, j, :, :])/n_baseline**2\n",
    "            NST_resp[i, j] = np.sum(T_resp[i, j, :, :])/n_response**2\n",
    "\n",
    "    # PCIST\n",
    "    NST_diff = NST_resp - k * NST_base\n",
    "    ixs = np.argmax(NST_diff, axis=0)\n",
    "    max_thresholds = np.array([thresholds[ix, i] for ix, i in zip(ixs, range(n_dims))])\n",
    "    dNST = np.array([NST_diff[ix, i] for ix, i in zip(ixs, range(n_dims))]) * n_response\n",
    "    dNST = [x if x>0 else 0 for x in dNST]\n",
    "\n",
    "    temp = np.zeros((n_dims, n_response, n_response))\n",
    "    temp2 = np.zeros((n_dims, n_baseline, n_baseline))\n",
    "    for i in range(n_dims):\n",
    "        temp[i, :, :] = T_resp[ixs[i], i, :, :]\n",
    "        temp2[i, :, :] = T_base[ixs[i], i, :, :]\n",
    "    T_resp = temp\n",
    "    T_base = temp2\n",
    "\n",
    "    return {'dNST':dNST, 'n_dims':n_dims,\n",
    "    'D_base':D_base, 'D_resp':D_resp, 'T_base':T_base,'T_resp':T_resp,\n",
    "    'thresholds':thresholds, 'NST_diff':NST_diff, 'NST_resp':NST_resp, 'NST_base':NST_base,'max_thresholds':max_thresholds}\n",
    "\n",
    "\n",
    "def recurrence_matrix(signal, mode, thr=None):\n",
    "    ''' Calculates distance, recurrence or transition matrix. Signal can be\n",
    "    embedded (m, n_times) or not (, n_times).\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray\n",
    "        Time-series; may be a 1D (time,) or a m-dimensional array (m, time) for\n",
    "        time-delay embeddeding.\n",
    "    mode : str\n",
    "        Specifies calculated matrix: 'distance', 'recurrence' or 'transition'\n",
    "    thr : float, optional\n",
    "        If transition matrix is chosen (`mode`=='transition'), specifies threshold value.\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        2D array containing specified matrix.\n",
    "    '''\n",
    "    if len(signal.shape) == 1:\n",
    "        signal = signal[np.newaxis, :]\n",
    "    n_dims = signal.shape[0]\n",
    "    n_times = signal.shape[1]\n",
    "\n",
    "    R = np.zeros((n_dims, n_times, n_times))\n",
    "    for i in range(n_dims):\n",
    "        D = np.tile(signal[i, :], (n_times, 1))\n",
    "        D = D - D.T\n",
    "        R[i, :, :] = D\n",
    "    R = np.linalg.norm(R, ord=2, axis=0)\n",
    "\n",
    "    mask = (R <= thr) if thr else np.zeros(R.shape).astype(bool)\n",
    "    if mode == 'distance':\n",
    "        R[mask] = 0\n",
    "        return R\n",
    "    if mode == 'recurrence':\n",
    "        return mask.astype(int)\n",
    "    if mode == 'transition':\n",
    "        return diff_matrix(mask.astype(int), symmetric=False)\n",
    "    return 0\n",
    "\n",
    "def distance2transition(dist_R, thr):\n",
    "    ''' Receives 2D distance matrix and calculates transition matrix. '''\n",
    "    mask = dist_R <= thr\n",
    "    R = diff_matrix(mask.astype(int), symmetric=False)\n",
    "    return R\n",
    "\n",
    "def distance2recurrence(dist_R, thr):\n",
    "    ''' Receives 2D distance matrix and calculates recurrence matrix. '''\n",
    "    mask = dist_R <= thr\n",
    "    return mask.astype(int)\n",
    "\n",
    "def diff_matrix(A, symmetric=False):\n",
    "    B = np.abs(np.diff(A))\n",
    "    if B.shape[1] != B.shape[0]:\n",
    "        B2 = np.zeros((B.shape[0], B.shape[1]+1))\n",
    "        B2[:, :-1] = B\n",
    "        B = B2\n",
    "    if symmetric:\n",
    "        B = (B + B.T)\n",
    "        B[B > 0] = 1\n",
    "    return B\n",
    "\n",
    "def calc_maxdim(eigenvalues, max_var):\n",
    "    ''' Get number of dimensions that accumulates at least `max_var`% of total variance'''\n",
    "    if max_var == 100:\n",
    "        return len(eigenvalues)\n",
    "    eigenvalues = np.sort(eigenvalues)[::-1] # Sort in descending order\n",
    "    var = eigenvalues ** 2\n",
    "    var_p = 100 * var/np.sum(var)\n",
    "    var_cum = np.cumsum(var_p)\n",
    "    max_dim = len(eigenvalues) - np.sum(var_cum >= max_var) + 1\n",
    "    return max_dim\n",
    "\n",
    "def dimension_embedding(x, L, tau):\n",
    "    '''\n",
    "    Returns time-delay embedding of vector.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        1D array time series.\n",
    "    L : int\n",
    "        Number of dimensions in the embedding.\n",
    "    tau : int\n",
    "        Number of samples in delay.\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        2D array containing embedded signal (L, time)\n",
    "    '''\n",
    "    assert len(x.shape) == 1, \"x must be one-dimensional array (n_times,)\"\n",
    "    n_times = x.shape[0]\n",
    "    s = np.zeros((L, n_times - (L-1) * tau))\n",
    "    ini = (L-1) * tau if L > 1 else None\n",
    "    s[0, :] = x[ini:]\n",
    "    for i in range(1, L):\n",
    "        ini = (L-i-1) * tau\n",
    "        end = -i * tau\n",
    "        s[i, :] = x[ini:end]\n",
    "    return s\n",
    "\n",
    "## PREPROCESS\n",
    "def preprocess_signal(signal_evk, times, time_window, baseline_corr=False, resample=None, avgref=False, **kwargs):\n",
    "    \n",
    "    #Comment: when baseline_corr, avgref=False these functions are NOT called        \n",
    "    assert signal_evk.shape[1] == len(times), 'Signal and Time arrays must be of the same size.'\n",
    "    if avgref:\n",
    "        signal_evk = avgreference(signal_evk)\n",
    "    if baseline_corr:\n",
    "        signal_evk = baseline_correct(signal_evk, times, delta=-50)\n",
    "   \n",
    "    #define time window for which input data are analyzed, get start and stop values of time_window are specified in par dictionary (start value in baseline_window, and stop value in response_window) \n",
    "    t_ini, t_end = time_window #time_window values specified in par (start value in baseline_window, and stop value in response_window)\n",
    "    ini_ix = get_time_index(times, t_ini) #get index of start value \n",
    "    end_ix = get_time_index(times, t_end) # get index of stop value\n",
    "    signal_evk = signal_evk[:, ini_ix:end_ix] # slice data array \n",
    "    times = times[ini_ix:end_ix] # slice time array\n",
    "    #if value is passed to resample argument the data will be resampled using fourier method (undersample_signal)\n",
    "    if resample:\n",
    "        signal_evk, times = undersample_signal(signal_evk, times, new_fs=resample)\n",
    "    return signal_evk, times\n",
    "\n",
    "def avgreference(signal):\n",
    "    ''' Performs average reference to signal. '''\n",
    "    new_signal = np.zeros(signal.shape)\n",
    "    channels_mean = np.mean(signal, axis=0)[np.newaxis]\n",
    "    new_signal = signal - channels_mean\n",
    "    return new_signal\n",
    "\n",
    "def undersample_signal(signal, times, new_fs):\n",
    "    '''\n",
    "    signal : (ch x times)\n",
    "    times : (times,) [ms]\n",
    "    new_fs : [hz]\n",
    "    '''\n",
    "    n_samples = int((times[-1]-times[0])/1000 * new_fs)\n",
    "    new_signal_evk, new_times = scipy.signal.resample(signal, n_samples, t=times, axis=1)\n",
    "    return new_signal_evk, new_times\n",
    "\n",
    "def baseline_correct(Y, times, delta=0):\n",
    "    ''' Baseline correct signal using times < delta '''\n",
    "    \n",
    "    #evaluate function (don't forget to # the variables when done evaluating)\n",
    "    #Y = data_pci\n",
    "    #times = time\n",
    "    #delta = 0\n",
    "    \n",
    "    newY = np.zeros(Y.shape)\n",
    "    #get index of baseline (integer scalar)\n",
    "    onset_ix = get_time_index(times, delta)\n",
    "    #calculates mean of baseline\n",
    "    baseline_mean = np.mean(Y[:, :onset_ix], axis=1)[np.newaxis]\n",
    "    #subtracts the mean baseline of each channel from all samples\n",
    "    newY = Y - baseline_mean.T\n",
    "    #evaluate if baseline mean is zero after subraction (close enough is a boolean, --> True if baseline is zero)    \n",
    "    close_enough = np.all(np.isclose(np.mean(newY[:, :onset_ix], axis=1), 0, atol=1e-08))\n",
    "    assert close_enough, \"Baseline mean is not zero\"\n",
    "    return newY\n",
    "\n",
    "def get_time_index(times, onset=0):\n",
    "    ''' Returns index of first time greater then delta. For delta=0 gets index of\n",
    "    first non-negative time.\n",
    "    '''\n",
    "    return np.sum(times < onset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def files_to_list (directory = r\"D:\\Data_scripts\\MUA_doubleshank_Neuronexus_probes\\2020-12-07\", filename_ending = \"Rec_7_201207_132859.rhs\" ):\n",
    "    \"\"\"returns absolute file_paths of data files as list of strings\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory: specify the directory where files are located; must be string or converted to raw string (r'...')\n",
    "    \n",
    "    filename_ending:  specifiy the file ending e.g. '.npy' , 'NOT_rm.npy'\n",
    "    \"\"\"\n",
    "    \n",
    "    ####change to directory where files are located, if system can not find the path try to convert to raw string, r'....'\n",
    "    os.chdir(directory)\n",
    "    ####empty list for filepaths: file_path\n",
    "    file_path = []\n",
    "    file_name = []\n",
    "    ####for loop appends filename with specific ending to file_path\n",
    "    for filename in os.listdir(directory):\n",
    "       if filename.endswith(filename_ending):\n",
    "           ###creates absolute filepath by merging directory with filename\n",
    "           file_path.append(os.path.join(directory, filename))\n",
    "           file_name.append(filename)\n",
    "    return file_path, file_name\n",
    "\n",
    "\n",
    "def sliding_window(start = 0, stop = 600, bin_step_ms = 80, factor =1.25 ):\n",
    "    \"\"\"    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start : (int) --> the start value of the interval in ms. The default is 0. \n",
    "    \n",
    "    stop : (int), --> the stop value of the interval in ms.  The default is 600.\n",
    "    \n",
    "    bin_step_ms : (int) --> the step size in ms the window is slided over the interval.  The default is 5.\n",
    "    \n",
    "    factor : (int), --> determines the size of the sliding window, calculated by bin_step x factor (e.g.  20ms = 5ms  x 4 ). The default is 4.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lst : list of tuples containing 2 integers in ms (x1,y1), (x2,y2),....--> The last tuple (xn, yn) is <= the stop value. Pass  tuple into 'response_window':(x,y) of **par  (pci_calc)\n",
    "    \n",
    "    interval1 : time array of the specified start-stop interval in ms at given bin_step_size (interval <= stop value)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #Parameters for testing, delete or # when finished\n",
    "    #start = 0\n",
    "    #stop = 600\n",
    "    #bin_step_ms = 80\n",
    "    #factor = 1.25\n",
    "    \n",
    "    #create time interval with start, stop and bin_step_ms size: interval1 (1-D, the start values of the response window)\n",
    "    interval1 = np.arange(start, (stop + bin_step_ms), bin_step_ms)\n",
    "    #the length of the time window used for calculating PCI_st: window\n",
    "    window = (bin_step_ms * factor)\n",
    "    \n",
    "    #add window to interval1 to obtain  the stop values of the response window: interval2\n",
    "    interval2 = (interval1 + window).astype('int')\n",
    "    \n",
    "    #find indices in interval2 where values <= stop: indices\n",
    "    indices = np.where(interval2 <= stop)[0]\n",
    "    \n",
    "    #slice interva11 and interval2 according to indices: interval1_sl, interval2_sl\n",
    "    interval1_sl = interval1[indices]\n",
    "    interval2_sl = interval2[indices]\n",
    "    \n",
    "   \n",
    "    \n",
    "    lst  =[(i,ii) for i,ii in zip(interval1_sl, interval2_sl)]\n",
    "    \n",
    "    return lst, interval1_sl\n",
    "    \n",
    "    \n",
    "def plot_pci_st(x,y,z, title = '_', anesthesia='Sevofluran 2.65%'):\n",
    "    \"\"\"    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : (1-D, array or list), the time data returned by sliding_window func\n",
    "    y : (1-D, array or list), the pci_st data returned by sliding_window func\n",
    "\n",
    "    plots x (time), y(control in black), z(drug in red) and  labels and title \n",
    "    \"\"\"\n",
    "    \n",
    "    #parameters for testing\n",
    "    #x = time_sl_window\n",
    "    #y = pci_st_100ms_w\n",
    "    #title = 'example'\n",
    "    \n",
    "    #convert  from ms to s:\n",
    "    x = x/1000\n",
    "    \n",
    "    _ = plt.plot(x,y, 'k',  label = 'Wake (ctrl)')\n",
    "    _ = plt.plot(x, z, 'r', label = anesthesia)\n",
    "    plt.xlabel('Time (s) ', fontsize = 25)\n",
    "    plt.ylabel('PCI_st', fontsize=25)    \n",
    "    plt.title (title, fontsize=20)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.axis([-0.02, 0.55, -2, 30])\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def create_directory (parent_dir = '_', directory= '_'):\n",
    "    \"\"\"create a directory within a specified parent directory\"\"\"\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.mkdir(path)\n",
    "\n",
    " \n",
    "def plot_paired_dot (before, after, title='PCIst_80to600ms_eeg', y_label='PCIst', y1=-0.2, y2=10):\n",
    "    \"\"\"returns plot which plots paired data before and after treatment + box plot on top \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    before: Pandas dataframe (1-D) or array-like containing data of before treatment group\n",
    "    \n",
    "    after:  Pandas dataframe (1-D) or array-like containing data of after treatment group\n",
    "    \n",
    "    y1= lower y-axis limit\n",
    "    \n",
    "    y2= upper y-axis limit\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #check if object is a pd.series, if yes append values to list\n",
    "    \n",
    "    if isinstance(before, pd.Series) == True:\n",
    "    #convert dataframes to arrays\n",
    "        before = before.values.tolist()\n",
    "        after =  after.values.tolist()\n",
    "    \n",
    "    #plotting the points before treatment\n",
    "    _= plt.scatter(np.zeros(len(before)), before, alpha=0.4,s = 40)\n",
    "    #plotting the points after treatment \n",
    "    _= plt.scatter(np.ones(len(after)), after, alpha=0.4, s = 40)\n",
    "    \n",
    "    \n",
    "    ####plot lines connecting each paired before and after treatment\n",
    "    #loop over all indices of input array\n",
    "    for i in range(len(before)):\n",
    "        _ = plt.plot([0,1], [before[i], after[i]], c ='k', linewidth=0.2)\n",
    "    #rename the xlabels\n",
    "    \n",
    "    #plot a boxplot on top of data\n",
    "    plt.boxplot([before, after], positions = [0,1])\n",
    "    \n",
    "    plt.xticks([0,1], ['Wake', 'Sevo'], fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.ylabel(y_label, fontsize=20)\n",
    "    plt.title(str(title), fontsize=20)\n",
    "    plt.axis([-0.2,1.2,y1, y2])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.gca().spines['top'].set_visible(True)\n",
    "    plt.gca().spines['right'].set_visible(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#parent directory for adding pci directory\n",
    "os.chdir(r'D:\\Data_scripts\\MUA_doubleshank_Neuronexus_probes\\2021_08_12\\analysis')\n",
    "parent_dir1 = os.getcwd()\n",
    "\n",
    "\n",
    "#parent directory where preprocessed data are located\n",
    "os.chdir(r'D:\\Data_scripts\\MUA_doubleshank_Neuronexus_probes\\2021_08_12\\analysis\\lfp')\n",
    "#parent directory where preprocessed data are located\n",
    "parent_dir2 = os.getcwd()\n",
    "\n",
    "\n",
    "#parent directory to which datafame is saved\n",
    "os.chdir(r'D:\\Data_scripts\\MUA_doubleshank_Neuronexus_probes\\2021_08_12\\analysis\\pci')\n",
    "#parent directory where preprocessed data are located\n",
    "parent_dir3 = os.getcwd()\n",
    "#file name for saving dataframe\n",
    "file_name_df = '/df_pci_eeg_lfp_A5_A7_A8_A9_A10_pairref.pkl'\n",
    "#absolute path for saving dataframe\n",
    "path_df = parent_dir3 + file_name_df\n",
    "\n",
    "\n",
    "###for dataframe, specify state of animal according to f_name_lst: state1\n",
    "state1=['wake', 'anesthetized(Sevo 3.1%)'] \n",
    "\n",
    "###for dataframe, specify if pci_st was calculated from eeg or lfp : eeg_or_lfp1\n",
    "eeg_or_lfp1=['lfp', 'lfp'] \n",
    "\n",
    "\n",
    "###for dataframe, specify if referenced or not: referenced1\n",
    "referenced1=['pairref', 'pairref'] \n",
    "\n",
    "\n",
    "###for dataframe, specify animal id (e.g. A8): animal_id1\n",
    "animal_id1=['A10', 'A10'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Call functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###create empty dataframe with specified column names to append pci_st values: df_pci\n",
    "#df_pci_all_data = pd.DataFrame(columns=['pci_st_60to180ms', 'nst_60to180ms', 'pci_st_80to600ms', 'nst_80to600ms', 'pci_st_0to300ms', 'nst_0to300ms', 'resp_window', 'pci_st_100ms_slide_window', 'state', 'eeg_or_lfp', 'referenced', 'animal_id',  'f_name'])\n",
    "\n",
    "###load dataframe whicjh collects PCI_st data across animals\n",
    "df_pci_all_data = pd.read_pickle('D:/Data_scripts/MUA_doubleshank_Neuronexus_probes/2021_08_12/analysis/pci/df_pci_eeg_A5_A7_A8_A9_A10_pairref.pkl') \n",
    "\n",
    "\n",
    "###get list of absolute filepaths and filenames of recorded data in target directory: f_path_lst, f_name_lst\n",
    "f_path_lst, f_name_lst = files_to_list(directory=parent_dir2, filename_ending = \"rec1__210812_111942.rhs_lfp_preprocessed_shank_pairref_.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9866666666666664, 4.8999999999999995, 6.124561220950398]\n"
     ]
    }
   ],
   "source": [
    "###loop over parameters which are appended to dataframe\n",
    "\n",
    "for f_path, f_name, state2, eeg_or_lfp2, referenced2, animal_id2 in zip(f_path_lst, f_name_lst, state1, eeg_or_lfp1, referenced1, animal_id1):\n",
    "\n",
    "\n",
    "    ###create empty list for appending pci_st values calculated in a 100ms time window: pci_st_100ms_w\n",
    "    pci_st_100ms_w =[]\n",
    "    \n",
    "\n",
    "\n",
    "    ###load data: data (samples x channels x trials)\n",
    "    data = np.load(f_path)\n",
    "    \n",
    "    ###mean over data trials: data_m (samples x channels)\n",
    "    data_m = np.mean(data, axis = 2)\n",
    "    \n",
    "    ###transpose data_m for calc_PCIst: data_pci\n",
    "    data_pci = np.transpose(data_m)\n",
    "    \n",
    "    ###get start and stop values of data_pci samples in ms: start, stop ; create then time array for PCIst: time\n",
    "    start = (np.size(data_pci, axis =1)-1) * -1 #multiply with -1 to get baseline start value before stim (negative value required by calc_PCIst)\n",
    "    stop = (np.size(data_pci, axis =1)-1)      #after stimulation, the postive stop value \n",
    "    time = np.linspace(start, stop, num = np.size(data_pci, axis = 1))\n",
    "    \n",
    "    resp_w, time_sl_window = sliding_window(start = 0, stop = 600, bin_step_ms=20, factor = 5)\n",
    "    \n",
    "    \n",
    "    ###make list with repeated entires of file_name depending on length of resp_wi file_name_tile\n",
    "    file_name_tile = np.tile(f_name, len(resp_w))\n",
    "\n",
    "    ###make list with repeated entires of state2 depending on length of resp_w: state_tile\n",
    "    state_tile = np.tile(state2, len(resp_w))\n",
    "    \n",
    "    ###make list with repeated entires of eeg_or_lfp_2 depending on length of resp_w: eeg_or_lfp_tile\n",
    "    eeg_or_lfp_tile = np.tile(eeg_or_lfp2, len(resp_w))\n",
    "    \n",
    "    ###make list with repeated entires of referenced2 depending on length of resp_w: referenced_tile\n",
    "    referenced_tile = np.tile(referenced2, len(resp_w))\n",
    "    \n",
    "    ###make list with repeated entires of animal_id depending on length of resp_wi: animal_id_tile\n",
    "    animal_id_tile = np.tile(animal_id2, len(resp_w))\n",
    "\n",
    "        \n",
    "    \n",
    "    ###calculate pci_st for a 100ms sliding window specified in resp_w\n",
    "    for i in resp_w: \n",
    "    \n",
    "        ###specify the parameters used for calculating PCIst: par\n",
    "        par = {'baseline_window':(-500,-5), 'response_window': i, 'k':1.2, 'min_snr':2.0, 'max_var':99, 'embed':False,'n_steps':100}\n",
    "        ###calculate the pci_st: pci_st      \n",
    "        pci_st = calc_PCIst(data_pci, time, full_return=True, **par)\n",
    "        \n",
    "        \n",
    "        ###append PCI values of 100ms long response windows (resp_w) to list: pci_st_100ms_w\n",
    "        pci_st_100ms_w.append(pci_st['PCI'])\n",
    "        \n",
    "\n",
    "    ### calculate PCIst for the specified response_window \n",
    "    par = {'baseline_window':(-500,-5), 'response_window': (60,180), 'k':1.2, 'min_snr':2.0, 'max_var':99, 'embed':False,'n_steps':100}\n",
    "    ###calculate the pci_st: pci_st      \n",
    "    pci_st_60to180ms = calc_PCIst(data_pci, time, full_return=True, **par)\n",
    "    \n",
    "    \n",
    "    ### calculate PCIst for a specified response_window \n",
    "    par = {'baseline_window':(-500,-5), 'response_window': (80,600), 'k':1.2, 'min_snr':2.0, 'max_var':99, 'embed':False,'n_steps':100}\n",
    "    ###calculate the pci_st: pci_st      \n",
    "    pci_st_80to600ms = calc_PCIst(data_pci, time, full_return=True, **par)\n",
    "\n",
    "\n",
    "    ### calculate PCIst for the specified response_window \n",
    "    par = {'baseline_window':(-500,-5), 'response_window': (0,300), 'k':1.2, 'min_snr':2.0, 'max_var':99, 'embed':False,'n_steps':100}\n",
    "    ###calculate the pci_st: pci_st      \n",
    "    pci_st_0to300ms = calc_PCIst(data_pci, time, full_return=True, **par)\n",
    "    print(pci_st_0to300ms['dNST'])\n",
    "\n",
    "\n",
    "    ### calculate PCIst for the specified response_window \n",
    "    par = {'baseline_window':(-500,-5), 'response_window': (0,600), 'k':1.2, 'min_snr':2.0, 'max_var':99, 'embed':False,'n_steps':100}\n",
    "    ###calculate the pci_st: pci_st      \n",
    "    pci_st_0to600ms = calc_PCIst(data_pci, time, full_return=True, **par)\n",
    "\n",
    "    ### calculate PCIst for the specified response_window \n",
    "    par = {'baseline_window':(-500,-5), 'response_window': (40,220), 'k':1.2, 'min_snr':2.0, 'max_var':99, 'embed':False,'n_steps':100}\n",
    "    ###calculate the pci_st: pci_st      \n",
    "    pci_st_40to220ms = calc_PCIst(data_pci, time, full_return=True, **par)\n",
    "\n",
    "    ### calculate PCIst for the specified response_window \n",
    "    par = {'baseline_window':(-500,-5), 'response_window': (40,320), 'k':1.2, 'min_snr':2.0, 'max_var':99, 'embed':False,'n_steps':100}\n",
    "    ###calculate the pci_st: pci_st      \n",
    "    pci_st_40to320ms = calc_PCIst(data_pci, time, full_return=True, **par)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###create dictionarry from key(columns labels) value pairs (returned function values ), : d\n",
    "    d = dict(pci_st_60to180ms = pci_st_60to180ms['PCI'], nst_60to180ms = pci_st_60to180ms['dNST'], pci_st_80to600ms = pci_st_80to600ms['PCI'], nst_80to600ms = pci_st_80to600ms['dNST'], pci_st_0to300ms = pci_st_0to300ms['PCI'] , nst_0to300ms= pci_st_0to300ms['dNST'], pci_st_0to600ms = pci_st_0to600ms['PCI'] , nst_0to600ms= pci_st_0to600ms['dNST'], pci_st_40to220ms = pci_st_40to220ms['PCI'] , nst_40to220ms= pci_st_40to220ms['dNST'], pci_st_40to320ms = pci_st_40to320ms['PCI'] , nst_40to320ms= pci_st_40to320ms['dNST'], resp_window = resp_w, pci_st_100ms_slide_window = pci_st_100ms_w, state=state_tile, eeg_or_lfp = eeg_or_lfp_tile, referenced = referenced_tile, animal_id = animal_id_tile, f_name = file_name_tile)\n",
    "    \n",
    "    \n",
    "    ##create data frame with pd.series function (necessary for creating dataframe if arrays not same size).\n",
    "    df_pci = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in d.items()]))\n",
    "    \n",
    "    \n",
    "    ###append df_pci to df_pci_all_data\n",
    "    df_pci_all_data = df_pci_all_data.append(df_pci, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pci_st_60to180ms</th>\n",
       "      <th>nst_60to180ms</th>\n",
       "      <th>pci_st_80to600ms</th>\n",
       "      <th>nst_80to600ms</th>\n",
       "      <th>pci_st_0to300ms</th>\n",
       "      <th>nst_0to300ms</th>\n",
       "      <th>pci_st_0to600ms</th>\n",
       "      <th>nst_0to600ms</th>\n",
       "      <th>pci_st_40to220ms</th>\n",
       "      <th>nst_40to220ms</th>\n",
       "      <th>pci_st_40to320ms</th>\n",
       "      <th>nst_40to320ms</th>\n",
       "      <th>resp_window</th>\n",
       "      <th>pci_st_100ms_slide_window</th>\n",
       "      <th>state</th>\n",
       "      <th>eeg_or_lfp</th>\n",
       "      <th>referenced</th>\n",
       "      <th>animal_id</th>\n",
       "      <th>f_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.95</td>\n",
       "      <td>2.433333</td>\n",
       "      <td>13.667684</td>\n",
       "      <td>4.103846</td>\n",
       "      <td>21.122281</td>\n",
       "      <td>6.960000</td>\n",
       "      <td>26.081502</td>\n",
       "      <td>8.103333</td>\n",
       "      <td>11.723887</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>16.134588</td>\n",
       "      <td>4.078571</td>\n",
       "      <td>(0, 100)</td>\n",
       "      <td>7.899043</td>\n",
       "      <td>wake</td>\n",
       "      <td>eeg</td>\n",
       "      <td>noref</td>\n",
       "      <td>A5</td>\n",
       "      <td>rec2_210325_140833.rhs_eeg_preprocessed_noref_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.662407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.822281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.438536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.743233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.358544</td>\n",
       "      <td>(20, 120)</td>\n",
       "      <td>5.365440</td>\n",
       "      <td>wake</td>\n",
       "      <td>eeg</td>\n",
       "      <td>noref</td>\n",
       "      <td>A5</td>\n",
       "      <td>rec2_210325_140833.rhs_eeg_preprocessed_noref_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.901431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.340000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.539632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.536209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.697473</td>\n",
       "      <td>(40, 140)</td>\n",
       "      <td>2.956587</td>\n",
       "      <td>wake</td>\n",
       "      <td>eeg</td>\n",
       "      <td>noref</td>\n",
       "      <td>A5</td>\n",
       "      <td>rec2_210325_140833.rhs_eeg_preprocessed_noref_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(60, 160)</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>wake</td>\n",
       "      <td>eeg</td>\n",
       "      <td>noref</td>\n",
       "      <td>A5</td>\n",
       "      <td>rec2_210325_140833.rhs_eeg_preprocessed_noref_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(80, 180)</td>\n",
       "      <td>5.780000</td>\n",
       "      <td>wake</td>\n",
       "      <td>eeg</td>\n",
       "      <td>noref</td>\n",
       "      <td>A5</td>\n",
       "      <td>rec2_210325_140833.rhs_eeg_preprocessed_noref_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pci_st_60to180ms  nst_60to180ms  pci_st_80to600ms  nst_80to600ms  \\\n",
       "0              5.95       2.433333         13.667684       4.103846   \n",
       "1               NaN       3.516667               NaN       2.662407   \n",
       "2               NaN            NaN               NaN       6.901431   \n",
       "3               NaN            NaN               NaN            NaN   \n",
       "4               NaN            NaN               NaN            NaN   \n",
       "\n",
       "   pci_st_0to300ms  nst_0to300ms  pci_st_0to600ms  nst_0to600ms  \\\n",
       "0        21.122281      6.960000        26.081502      8.103333   \n",
       "1              NaN      5.822281              NaN      4.438536   \n",
       "2              NaN      8.340000              NaN     13.539632   \n",
       "3              NaN           NaN              NaN           NaN   \n",
       "4              NaN           NaN              NaN           NaN   \n",
       "\n",
       "   pci_st_40to220ms  nst_40to220ms  pci_st_40to320ms  nst_40to320ms  \\\n",
       "0         11.723887       3.444444         16.134588       4.078571   \n",
       "1               NaN       2.743233               NaN       3.358544   \n",
       "2               NaN       5.536209               NaN       8.697473   \n",
       "3               NaN            NaN               NaN            NaN   \n",
       "4               NaN            NaN               NaN            NaN   \n",
       "\n",
       "  resp_window  pci_st_100ms_slide_window state eeg_or_lfp referenced  \\\n",
       "0    (0, 100)                   7.899043  wake        eeg      noref   \n",
       "1   (20, 120)                   5.365440  wake        eeg      noref   \n",
       "2   (40, 140)                   2.956587  wake        eeg      noref   \n",
       "3   (60, 160)                   5.300000  wake        eeg      noref   \n",
       "4   (80, 180)                   5.780000  wake        eeg      noref   \n",
       "\n",
       "  animal_id                                             f_name  \n",
       "0        A5  rec2_210325_140833.rhs_eeg_preprocessed_noref_...  \n",
       "1        A5  rec2_210325_140833.rhs_eeg_preprocessed_noref_...  \n",
       "2        A5  rec2_210325_140833.rhs_eeg_preprocessed_noref_...  \n",
       "3        A5  rec2_210325_140833.rhs_eeg_preprocessed_noref_...  \n",
       "4        A5  rec2_210325_140833.rhs_eeg_preprocessed_noref_...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the head and tail of the dataframe\n",
    "df_pci_all_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
